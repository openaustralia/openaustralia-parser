require 'speeches'
require 'id'
require 'speech'
require 'mechanize_proxy'

class HansardHeading
  def initialize
    @title = ""
    @subtitle = ""
  end
  
  def output(x, newtitle, newsubtitle, speech_id, url)
    # Only add headings if they have changed
    if newtitle != @title
      x.tag!("major-heading", newtitle, :id => speech_id, :url => url)
      speech_id.next
    end
    if newtitle != @title || newsubtitle != @subtitle
      x.tag!("minor-heading", newsubtitle, :id => speech_id, :url => url)
      speech_id.next
    end
    @title = newtitle
    @subtitle = newsubtitle
  end
end

class HansardParser
  
  def HansardParser.parse_date(date, xml_filename, people)
    conf = Configuration.new

    # Required to workaround long viewstates generated by .NET (whatever that means)
    # See http://code.whytheluckystiff.net/hpricot/ticket/13
    Hpricot.buffer_size = 262144

    agent = MechanizeProxy.new
    agent.cache_subdirectory = date.to_s

    url = "http://parlinfoweb.aph.gov.au/piweb/browse.aspx?path=Chamber%20%3E%20House%20Hansard%20%3E%20#{date.year}%20%3E%20#{date.day}%20#{Date::MONTHNAMES[date.month]}%20#{date.year}"
    begin
      page = agent.get(url)
      # HACK: Don't know why if the page isn't found a return code isn't returned. So, hacking around this.
      if page.title == "ParlInfo Web - Error"
        throw "ParlInfo Web - Error"
      end
    rescue
      puts "WARNING: Could not retrieve overview page for date #{date}"
      return
    end
    #if page.title == "ParlInfo Web - Error"
    #  puts "WARNING: Could not retrieve overview page for date #{date}"
    #  return
    #end
    parse_day_page(page, date, agent, people, xml_filename)
  end
  
  # Replace unicode characters by their equivalent
  def HansardParser.replace_unicode(text)
    t = text.gsub("\342\200\230", "'")
    t.gsub!("\342\200\231", "'")
    t.gsub!("\342\200\224", "-")
    t.each_byte do |c|
      if c > 127
        puts "Warning: Found invalid characters in: #{t.dump}"
      end
    end
    t
  end
  
  def HansardParser.parse_sub_day_speech_page(sub_page, x, heading, speech_id, people, date, time, url)
    newtitle = sub_page.search('div#contentstart div.hansardtitle').map { |m| m.inner_html }.join('; ')
    newsubtitle = sub_page.search('div#contentstart div.hansardsubtitle').map { |m| m.inner_html }.join('; ')
    # Replace any unicode characters
    newtitle = HansardParser.replace_unicode(newtitle)
    newsubtitle = HansardParser.replace_unicode(newsubtitle)

    heading.output(x, newtitle, newsubtitle, speech_id, url)

    speeches = Speeches.new

    # Untangle speeches from subspeeches
    speech_content = Hpricot::Elements.new
    content = sub_page.search('div#contentstart > div.speech0 > *')
    tag_classes = content.map{|e| e.attributes["class"]}
    subspeech0_index = tag_classes.index("subspeech0")
    paraitalic_index = tag_classes.index("paraitalic")

    if subspeech0_index.nil?
      subspeech_index = paraitalic_index
    elsif paraitalic_index.nil?
      subspeech_index = subspeech0_index
    else
      subspeech_index = min(subspeech0_index, paraitalic_index)
    end

    if subspeech_index
      speech_content = content[0..subspeech_index-1]
      subspeeches_content = content[subspeech_index..-1]
    else
      speech_content = content
    end
    # Extract speaker name from link
    speaker = extract_speaker_from_talkername_tag(speech_content, people, date)
    speeches.add_speech(speaker, time, url, speech_id,
      clean_speech_content(url, speech_content))

    if subspeeches_content
      process_subspeeches(subspeeches_content, people, date, speeches, time, url, speech_id, speaker)
    end
    speeches.write(x)   
  end
  
  def HansardParser.parse_sub_day_page(link_text, sub_page, x, heading, speech_id, people, date)
    # Only going to consider speeches for the time being
    if link_text =~ /^Speech:/
      # Link text for speech has format:
      # HEADING > NAME > HOUR:MINS:SECS
      split = link_text.split('>').map{|a| a.strip}
      puts "Warning: Expected split to have length 3" unless split.size == 3
      time = split[2]
      # Extract permanent URL of this subpage. Also, quoting because there is a bug
      # in XML Builder that for some reason is not quoting attributes properly
      url = quote(sub_page.links.text("[Permalink]").uri.to_s)
      
      parse_sub_day_speech_page(sub_page, x, heading, speech_id, people, date, time, url)
    elsif link_text == "Official Hansard" || link_text =~ /^Start of Business/ || link_text == "Adjournment"
      # Do nothing - skip this entirely
    elsif link_text =~ /^Procedural text:/ || link_text =~ /^QUESTIONS WITHOUT NOTICE:/ || link_text =~ /^QUESTIONS IN WRITING:/ ||
      link_text =~ /^Division:/
      puts "WARNING: Not yet supporting: #{link_text}"
    else
      puts "WARNING: Unsupported: #{link_text}"
    end
  end

  def HansardParser.parse_day_page(page, date, agent, people, xml_filename)
    xml = File.open(xml_filename, 'w')
    x = Builder::XmlMarkup.new(:target => xml, :indent => 1)

    heading = HansardHeading.new

    speech_id = Id.new("uk.org.publicwhip/debate/#{date}.")

    x.instruct!
    x.publicwhip do
      # Structure of the page is such that we are only interested in some of the links
      page.links[30..-4].each do |link|
        parse_sub_day_page(link.to_s, agent.click(link), x, heading, speech_id, people, date)
      end
    end

    xml.close
  end

  private
  
  def HansardParser.process_subspeeches(subspeeches_content, people, date, speeches, time, url, speech_id, speaker)
    # Now extract the subspeeches
    subspeeches_content.each do |e|
      tag_class = e.attributes["class"]
      if tag_class == "subspeech0" || tag_class == "subspeech1"
        speaker = extract_speaker_from_talkername_tag(e, people, date) || extract_speaker_in_interjection(e, people, date)
      elsif tag_class == "paraitalic"
        speaker = nil
      end
      speeches.add_speech(speaker, time, url, speech_id, clean_speech_content(url, e))
    end
  end

  def HansardParser.clean_speech_content(base_url, content)
    doc = Hpricot(content.to_s)
    doc.search('div.speechType').remove
    doc.search('span.talkername').remove
    doc.search('span.talkerelectorate').remove
    doc.search('span.talkerrole').remove
    doc.search('hr').remove
    make_motions_and_quotes_italic(doc)
    remove_subspeech_tags(doc)
    fix_links(base_url, doc)
    make_amendments_italic(doc)
    fix_attributes_of_p_tags(doc)
    fix_attributes_of_td_tags(doc)
    # Do pure string manipulations from here
    text = doc.to_s
    text = text.gsub("(\342\200\224)", '')
    text = text.gsub(/([^\w])\342\200\224/) {|m| m[0..0]}
    text = text.gsub(/\(\d{1,2}.\d\d a.m.\)/, '')
    text = text.gsub(/\(\d{1,2}.\d\d p.m.\)/, '')
    text = text.gsub('()', '')
    # Look for tags in the text and display warnings if any of them aren't being handled yet
    text.scan(/<[a-z][^>]*>/i) do |t|
      m = t.match(/<([a-z]*) [^>]*>/i)
      if m
        tag = m[1]
      else
        tag = t[1..-2]
      end
      allowed_tags = ["b", "i", "dl", "dt", "dd", "ul", "li", "a", "table", "td", "tr"]
      if !allowed_tags.include?(tag) && t != "<p>" && t != '<p class="italic">'
        puts "WARNING: Tag #{t} is present in speech contents"
        p text
      end
    end
    doc = Hpricot(text)
    #p doc.to_s
    doc
  end
  
  def HansardParser.fix_attributes_of_p_tags(content)
    content.search('p.parabold').wrap('<b></b>')
    content.search('p').each do |e|
      class_value = e.get_attribute('class')
      if class_value == "block" || class_value == "parablock" || class_value == "parasmalltablejustified" ||
          class_value == "parasmalltableleft" || class_value == "parabold"
        e.remove_attribute('class')
      elsif class_value == "paraitalic"
        e.set_attribute('class', 'italic')
      elsif class_value == "italic" && e.get_attribute('style')
        e.remove_attribute('style')
      end
    end
  end
  
  def HansardParser.fix_attributes_of_td_tags(content)
    content.search('td').each do |e|
      e.remove_attribute('style')
    end
  end
  
  def HansardParser.fix_links(base_url, content)
    content.search('a').each do |e|
      href_value = e.get_attribute('href')
      if href_value.nil?
        # Remove a tags
        e.swap(e.inner_html)
      else
        e.set_attribute('href', URI.join(base_url, href_value))
      end
    end
    content
  end
  
  def HansardParser.replace_with_inner_html(content, search)
    content.search(search).each do |e|
      e.swap(e.inner_html)
    end
  end
  
  def HansardParser.make_motions_and_quotes_italic(content)
    content.search('div.motion p').set(:class => 'italic')
    replace_with_inner_html(content, 'div.motion')
    content.search('div.quote p').set(:class => 'italic')
    replace_with_inner_html(content, 'div.quote')
    content
  end
  
  def HansardParser.make_amendments_italic(content)
    content.search('div.amendments div.amendment0 p').set(:class => 'italic')
    content.search('div.amendments div.amendment1 p').set(:class => 'italic')
    replace_with_inner_html(content, 'div.amendment0')
    replace_with_inner_html(content, 'div.amendment1')
    replace_with_inner_html(content, 'div.amendments')
    content
  end
  
  def HansardParser.remove_subspeech_tags(content)
    replace_with_inner_html(content, 'div.subspeech0')
    replace_with_inner_html(content, 'div.subspeech1')
    content
  end
  
  def HansardParser.quote(text)
    text.sub('&', '&amp;')
  end

  def HansardParser.extract_speaker_from_talkername_tag(content, people, date)
    tag = content.search('span.talkername a').first
    if tag
      lookup_speaker(tag.inner_html, people, date)
    end
  end

  def HansardParser.extract_speaker_in_interjection(content, people, date)
    if content.search("div.speechType").inner_html == "Interjection"
      text = strip_tags(content.search("div.speechType + *").first)
      m = text.match(/([a-z].*) interjecting/i)
      if m
        name = m[1]
        lookup_speaker(name, people, date)
      else
        m = text.match(/([a-z].*)â€”/i)
        if m
          name = m[1]
          lookup_speaker(name, people, date)
        end
      end
    else
      throw "Not an interjection"
    end
  end

  def HansardParser.lookup_speaker(speakername, people, date)
    if speakername.nil?
      speakername = "unknown"
    end

    # HACK alert (Oh you know what this whole thing is a big hack alert)
    if speakername =~ /^the speaker/i
      return people.house_speaker(date)
    # The name might be "The Deputy Speaker (Mr Smith)". So, take account of this
    elsif speakername =~ /^the deputy speaker/i
      # Check name in brackets
      match = speakername.match(/^the deputy speaker \((.*)\)/i)
      if match
        puts "WARNING: Deputy speaker is #{match[1]}"
        speakername = match[1]
      else
        return people.deputy_house_speaker(date)
      end
    elsif speakername =~ /^the clerk/i
      # TODO: Handle "The Clerk" correctly
      speakername = "unknown"
    end
    # Lookup id of member based on speakername
    if speakername.downcase == "unknown"
      nil
    else
      name = Name.title_first_last(speakername)
      matches = people.find_members_by_name_current_on_date(name, date)
      throw "Multiple matches for name #{speakername} found" if matches.size > 1
      throw "No match for name #{speakername} found" if matches.size == 0
      matches[0]
    end
  end

  def HansardParser.strip_tags(doc)
    str=doc.to_s
    str.gsub(/<\/?[^>]*>/, "")
  end

  def HansardParser.min(a, b)
    if a < b
      a
    else
      b
    end
  end
end
